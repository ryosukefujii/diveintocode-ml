{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qz4iEuEgAesa"
   },
   "source": [
    "# 線形回帰スクラッチ\n",
    "線形回帰のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "以下に雛形を用意してあります。このScratchLinearRegressionクラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jKgxbqNAySa"
   },
   "source": [
    "### 雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbS3xJHKA0aW"
   },
   "outputs": [],
   "source": [
    "# class ScratchLinearRegression():\n",
    "#     \"\"\"\n",
    "#     線形回帰のスクラッチ実装\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     num_iter : int\n",
    "#       イテレーション数\n",
    "#     lr : float\n",
    "#       学習率\n",
    "#     no_bias : bool\n",
    "#       バイアス項を入れない場合はTrue\n",
    "#     verbose : bool\n",
    "#       学習過程を出力する場合はTrue\n",
    "\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "#       パラメータ\n",
    "#     self.loss : 次の形のndarray, shape (self.iter,)\n",
    "#       学習用データに対する損失の記録\n",
    "#     self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "#       検証用データに対する損失の記録\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, num_iter, lr, bias, verbose):\n",
    "#         # ハイパーパラメータを属性として記録\n",
    "#         self.iter = num_iter # イテレーション数：データセットに含まれるデータが少なくとも1回は学習に用いられるのに必要な学習回数?\n",
    "#         #バッチサイズが決まれば自動的に決まる数値\n",
    "#         self.lr = lr #学習率\n",
    "#         self.bias = bias # モデルと学習データの平均的なズレ?\n",
    "#         self.verbose = verbose # 途中経過をコンソールに出力するか（初期値：True）?\n",
    "#         # 損失を記録する配列を用意\n",
    "#         self.loss = np.zeros(self.iter)\n",
    "#         self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "#     def fit(self, X, y, X_val=None, y_val=None):\n",
    "#         \"\"\"\n",
    "#         線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             学習用データの特徴量\n",
    "#         y : 次の形のndarray, shape (n_samples, )\n",
    "#             学習用データの正解値\n",
    "#         X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             検証用データの特徴量\n",
    "#         y_val : 次の形のndarray, shape (n_samples, )\n",
    "#             検証用データの正解値\n",
    "#         \"\"\"\n",
    "\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程を出力\n",
    "#             print()\n",
    "#         pass\n",
    "\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         線形回帰を使い推定する。\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#             次の形のndarray, shape (n_samples, 1)\n",
    "#             線形回帰による推定結果\n",
    "#         \"\"\"\n",
    "\n",
    "#         pass\n",
    "#         return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vQkjUY0A4ek"
   },
   "source": [
    "## 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。\n",
    "\n",
    "\b$x$ : 特徴量ベクトル\n",
    "\n",
    "$θ$ : パラメータベクトル\n",
    "\n",
    "$x_{j}$: j番目の特徴量\n",
    "\n",
    "$θ_{j}$: j番目のパラメータ（重み）\n",
    "\n",
    "特徴量の数$n$は任意の値に対応できる実装にしてください。\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\theta^T \\cdot x.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51RF88SkBzb1"
   },
   "source": [
    "### 雛形\n",
    "\n",
    "クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkh5AHL_CGgF"
   },
   "outputs": [],
   "source": [
    "def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbD4WT63Jrva"
   },
   "source": [
    "### 【問題1】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/FUZZY/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wN301b6Jv_o"
   },
   "outputs": [],
   "source": [
    "# データ取得\n",
    "df = pd.read_csv('../../house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "X = df['GrLivArea'].values\n",
    "# X = df[['GrLivArea', 'YearBuilt']].values\n",
    "# X = df[['1stFlrSF', 'GrLivArea']].values\n",
    "\n",
    "test = df['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仮定関数\n",
    "def _linear_hypothesis(X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "        x = 全行最初の列に値が1の列を追加されたデータX\n",
    "        w = θ0：yが0の時の接点, θ1,2,3...n:重み, n：特徴量の数\n",
    "        pred =  線形の仮定関数による推定結果（次の形のndarray, shape (n_samples, 1)）\n",
    "    \n",
    "    \"\"\"\n",
    "    if X.shape == (X.shape[0], ):\n",
    "        x = np.insert(X.reshape(-1, 1), 0, 1, axis=1) # 全行最初の列に値が1の列を追加\n",
    "    else:\n",
    "        x = np.insert(X, 0, 1, axis=1) # 全行最初の列に値が1の列を追加\n",
    "    w = np.random.normal(size=(x.shape[1],1))\n",
    "    hypo = x@w\n",
    "    return x, w, hypo\n",
    "\n",
    "x, w, hypo = _linear_hypothesis(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 1), array([[4923.25427294],\n",
       "        [3633.95373549],\n",
       "        [5141.97489983],\n",
       "        ...,\n",
       "        [6736.33315373],\n",
       "        [3104.41958617],\n",
       "        [3616.68631757]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo.shape, hypo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJ2jOqv4CHgu"
   },
   "source": [
    "## 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}[(h_\\theta(x^{(i)}) - y^{(i)} )x_{j}^{(i)}]\n",
    "$$\n",
    "\n",
    "$α$\n",
    " : 学習率\n",
    "\n",
    "$i$\n",
    " : サンプルのインデックス\n",
    "\n",
    "$j$\n",
    " : 特徴量のインデックス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBf9qGc9Jgut"
   },
   "source": [
    "### 雛形\n",
    "\n",
    "ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _gradient_descent(self, X, error):\n",
    "#     \"\"\"\n",
    "#     説明を記述\n",
    "\n",
    "#     \"\"\"\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雛形として用意されたメソッドや関数以外でも必要があれば各自作成して完成させてください。雛形を外れても問題ありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = hypo - test.reshape(-1, 1)\n",
    "# z = error.T@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _gradient_descent(X):\n",
    "#     \"\"\"\n",
    "   \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#         a : 学習率=lr\n",
    "     \n",
    "#     Returns\n",
    "#     -------\n",
    "#         m：サンプル数\n",
    "#         error：y予測結果 - 実際のyの値\n",
    "#         wj：最急降下法による重みの更新値を出力（次の形のndarray, shape (n_feature + 1, 1)  ）\n",
    "#     \"\"\"\n",
    "#     a = 0.9\n",
    "#     m = X.shape[0]\n",
    "#     error = hypo - test.reshape(-1, 1)\n",
    "#     wj = w - (a/m*(error.T@x).T)\n",
    "#     return m, error, wj\n",
    "\n",
    "# _gradient_descent(X)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m, error, wj = _gradient_descent(X)\n",
    "# wj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "仮定関数$ hθ(x) $の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(X):\n",
    "#     \"\"\"\n",
    "#     線形回帰を使い推定する。\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#         X : 次の形のndarray, shape (n_samples, n_features)\n",
    "#             サンプル\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#         次の形のndarray, shape (n_samples, 1)\n",
    "#         線形回帰による推定結果\n",
    "#     \"\"\"\n",
    "#     return pred\n",
    "\n",
    "# predict(X)\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】平均二乗誤差\n",
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。\n",
    "\n",
    "$$\n",
    "L(\\theta)=  \\frac{1 }{ m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$\n",
    "\n",
    "\n",
    "$m$: 入力されるデータの数\n",
    "\n",
    "$h_{θ}()$: 仮定関数\n",
    "\n",
    "$x_(i)$: i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$y_(i)$: i番目のサンプルの正解値\n",
    "\n",
    "なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MSE(y_pred, y):\n",
    "#     \"\"\"\n",
    "#     平均二乗誤差の計算\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "    \n",
    "\n",
    "#     Returns\n",
    "#     ----------\n",
    "#     mse : numpy.float\n",
    "#       平均二乗誤差\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "#     return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mse(y_pred, y):\n",
    "#         \"\"\"\n",
    "#     平均二乗誤差の計算\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#         y_pred : 次の形のndarray, shape (n_samples,)\n",
    "#         推定した値\n",
    "#         y : 次の形のndarray, shape (n_samples,)\n",
    "#         正解値\n",
    "        \n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#         mse：平均二乗誤差（mean square error, MSE）, type（numpy.float）\n",
    "#     \"\"\"\n",
    "        \n",
    "#         mse = 1/X.shape[0]*(np.sum(y_pred.reshape(-1, 1) - y.reshape(-1, 1))**2)\n",
    "#         return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "目的関数（損失関数） $J(θ)$ は次の式です。\n",
    "\n",
    "$$\n",
    "J(\\theta)=  \\frac{1 }{ 2m}  \\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})^2.\n",
    "$$\n",
    "\n",
    "$m$: 入力されるデータの数\n",
    "\n",
    "$hθ()$: 仮定関数\n",
    "\n",
    "$x(i)$: i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$y(i)$: i番目のサンプルの正解値\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**→クラス内に記述**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter # イテレーション数：データセットに含まれるデータが少なくとも1回は学習に用いられるのに必要な学習回数?\n",
    "        #バッチサイズが決まれば自動的に決まる数値\n",
    "        self.lr = lr #学習率\n",
    "        self.bias = bias # モデルと学習データの平均的なズレ?\n",
    "        self.verbose = verbose # 途中経過をコンソールに出力するか（初期値：True）?\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        # 傾き\n",
    "        self.coef_ = None\n",
    "\n",
    "# 仮定関数\n",
    "    def _linear_hypothesis(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            X : 次の形のndarray, shape (n_samples, n_features)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            x = 全行最初の列に値が1の列を追加されたデータX\n",
    "            w = θ0：yが0の時の接点, θ1,2,3...n:重み, n：特徴量の数\n",
    "            hypo =  線形の仮定関数による推定結果（次の形のndarray, shape (n_samples, 1)）\n",
    "\n",
    "        \"\"\"   \n",
    "        self.hypo = X@self.coef_\n",
    "        return self.hypo\n",
    "      \n",
    "        \n",
    "#  最急降下法\n",
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        self.coef_更新\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "            a : 学習率=lr\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            coef_：shape (n_feature + 1, 1)\n",
    "\n",
    "        \"\"\"\n",
    "        self.coef_ = self.coef_ - self.lr*(error.T@X).T/X.shape[0]\n",
    "\n",
    "        \n",
    "# 目的関数（損失関数）\n",
    "    def cost_func(self, X, y, X_val=None, y_val=None):\n",
    "        self.loss = 1/(2*X.shape[0])*np.sum((self.error)**2)\n",
    "        # X_val,y_val分岐\n",
    "        if X_val is not None and y_val is not None:\n",
    "            X_val = X_val.reshape(-1, X_val.shape[1])\n",
    "            self.val_loss = 1/(2*X_val.shape[0])*np.sum((self.error)**2)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "# Fit関数  \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        # X shape処理\n",
    "        X = X.reshape(-1, X.shape[1])\n",
    "                    \n",
    "        # バイアス分岐 \n",
    "        # True\n",
    "        if self.bias: \n",
    "            X = np.insert(X, 0, 1, axis=1)\n",
    "            self.coef_ = np.random.normal(size=(X.shape[1],1)) # coef(仮定関数の重み)の初期値を設定\n",
    "            self.count_iter = []\n",
    "            self.count = 0\n",
    "            self.loss_list = []\n",
    "            self.val_loss_list = []\n",
    "            for i in range(self.iter):\n",
    "                self.count +=1\n",
    "                self.count_iter.append(self.count)\n",
    "                # 仮定関数を実行し予測を更新\n",
    "                hypo = self._linear_hypothesis(X)\n",
    "                # 誤差を更新\n",
    "                self.error = hypo - y.reshape(-1, 1)\n",
    "                # 最急降下法による重みの更新\n",
    "                self._gradient_descent(X, self.error)\n",
    "                self.cost_func(X, y, X_val, y_val) \n",
    "                self.loss_list.append(self.loss)\n",
    "                self.val_loss_list.append(self.val_loss)\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                if self.verbose == True:\n",
    "                    print(\"{}回目の学習\".format(i+1))\n",
    "                   \n",
    "        # False\n",
    "        else: \n",
    "            self.coef_ = np.random.normal(size=(X.shape[1],1)) # coef(仮定関数の重み)の初期値を設定\n",
    "            self.count_iter = []\n",
    "            self.count = 0\n",
    "            self.loss_list = []\n",
    "            self.val_loss_list = []\n",
    "            for i in range(self.iter):\n",
    "                self.count +=1\n",
    "                self.count_iter.append(self.count)\n",
    "                # 仮定関数を実行し予測を更新\n",
    "                hypo = self._linear_hypothesis(X)\n",
    "                # 誤差を更新\n",
    "                self.error = hypo - y.reshape(-1, 1)\n",
    "                # 最急降下法による重みの更新\n",
    "                self._gradient_descent(X, self.error)\n",
    "                self.cost_func(X, y, X_val, y_val) \n",
    "                self.loss_list.append(self.loss)\n",
    "                self.val_loss_list.append(self.val_loss)\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                if self.verbose == True:\n",
    "                    print(\"{}回目の学習\".format(i+1))\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        predict = X@self.coef_    \n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = StandardScaler()\n",
    "if X.ndim > 1:\n",
    "    X = std.fit_transform(X.reshape(-1, X.shape[1]))\n",
    "    test = std.fit_transform(test.reshape(-1, 1))\n",
    "else:\n",
    "    X = std.fit_transform(X.reshape(-1, 1))\n",
    "    test = std.fit_transform(test.reshape(-1, 1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'num_iter':3000, 'lr':0.01, 'bias':True, 'verbose':False}\n",
    "model = ScratchLinearRegression(**param)\n",
    "\n",
    "param_fit = {'X':X_train, 'y':y_train, 'X_val':X_test, 'y_val':y_test}\n",
    "model.fit(**param_fit)\n",
    "# y_pred = model.predict(X_test)\n",
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse(y_pred, y_test)\n",
    "# mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learnによる実装との比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 1), (292, 1), (1168, 1), (292, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5421057428693639"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sklearn = LinearRegression()\n",
    "\n",
    "model_sklearn.fit(X_train, y_train)\n",
    "model_sklearn_pred = model_sklearn.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, model_sklearn_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。\n",
    "\n",
    "**プロット例**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://t.gyazo.com/teams/diveintocode/7977285221cd69d278434721fbe406e3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11f6dffd0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set()\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(model.count_iter, model.loss_list, label='train')\n",
    "plt.plot(model.count_iter, model.val_loss_list, label='val')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPc0Tm/puHo3qDAsiiF6SzB",
   "name": "Sprint 機械学習スクラッチ 線形回帰.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
