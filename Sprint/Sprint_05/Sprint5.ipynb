{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "target = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # データセットの用意\n",
    "# iris = load_iris()\n",
    "\n",
    "# # vesicolor, virginica\n",
    "# X = pd.DataFrame(iris.data)[50:].values\n",
    "# # # petal length, petal width\n",
    "\n",
    "# target = pd.DataFrame(iris.target)[50:].values\n",
    "# target = np.where(target < 2, 0, 1)\n",
    "\n",
    "# feature_names = pd.DataFrame(iris.feature_names)\n",
    "# target_names = pd.DataFrame(iris.target_names)\n",
    "\n",
    "# display(feature_names)\n",
    "# display(target_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = 0\n",
    "\n",
    "# # 特徴量１つ\n",
    "# X1 = X[:,[2]]\n",
    "# # 特徴量２つ\n",
    "# X2 = X[:,[2,3]]\n",
    "\n",
    "\n",
    "# if feature == 1:\n",
    "#     X = X1\n",
    "# elif feature == 2:\n",
    "#     X = X2\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42)\n",
    "X = X_train\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 決定木学習とは\n",
    "\n",
    "決定木学習は 決定木 と呼ばれる 木構造のグラフ を作る機械学習手法です。機械学習の分野では学習手法も単に「決定木」と呼ばれます。\n",
    "\n",
    "\n",
    "分類にも回帰にも使え、分類の場合3クラス以上の多値分類が可能です。ここでは基本となる分類のみを扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定木とは\n",
    "決定木は、属性 と 値 の組｛属性1：値1，属性2：値2, 属性3：値3,…，属性n：値n｝によって表現されたデータを、条件分岐を繰り返すことであるクラスに割り当てることができる木構造のグラフです。\n",
    "\n",
    "\n",
    "以下の例は会場の気温という属性の値によって、開催と中止のクラスに割り当てるグラフです。「会場の気温という属性の値は35以上かどうか」という条件分岐1回による決定木による分類が行えます。例えば36度がこの決定木にインプットされれば、中止というアウトプット（判断）ができます。\n",
    "\n",
    "![](https://t.gyazo.com/teams/diveintocode/ca1760b9db2eff08bc82102db1bf7eea.png)\n",
    "\n",
    "なお、「属性と値」は機械学習の分野では「特徴量の名前と特徴量の値」のことです。これ以降は単に特徴量という呼びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各種用語\n",
    "もう少し複雑な例で決定木で重要な用語を確認します。特徴量が「雨量」「屋内かどうか」「風の強さ」の3種類で、イベントの開催か中止かを分類する場合で考えてみます。訓練データを学習することで、以下のような決定木が作れます。\n",
    "\n",
    "![](https://t.gyazo.com/teams/diveintocode/c927a798dc2292cc05663301dde78632.png)\n",
    "\n",
    "丸で囲われたひとつひとつを ノード と呼びます。ノードには親子関係を考えることができ、例えば(0)のノードは(1)(2)(3)のノードの 親ノード と呼びます。逆に、(1)(2)(3)のノードは(0)のノードの 子ノード と呼びます。\n",
    "\n",
    "\n",
    "一番上の(0)は 根ノード 、 末端の(1)(4)(5)(7)(8)(9)のような分類結果を表すノードは 葉ノード と呼びます。\n",
    "\n",
    "\n",
    "条件分岐の矢印は エッジ と呼びます。あるノードから根ノードまでのエッジの数が 深さ です。(3)の深さは1、(6)の深さは2、(9)の深さは3という風になります。この決定木の最大の深さは3です。\n",
    "\n",
    "\n",
    "これは(0)に対して(1)(2)(3)の3つのノードが分かれている多岐分岐の決定木ですが、機械学習では2つにしか分かれないものが一般的です。学習時の複雑さを減らすためです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## どう決定木を作るか\n",
    "決定木の学習には様々なやり方が存在しますが、その中のある方法についてスクラッチを行いながら見ていきます。\n",
    "\n",
    "\n",
    "学習方法やハイパーパラメータ、訓練データ次第で作られる決定木は異なってきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推定を考える\n",
    "以下の場合、イベントは開催されるでしょうか。決定木を使って判断してください。\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align: center\">雨量[mm]</th>\n",
    "      <th style=\"text-align: center\">屋内かどうか</th>\n",
    "      <th style=\"text-align: center\">風の強さ[m/s]</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">2.5</td>\n",
    "      <td style=\"text-align: center\">1（屋内）</td>\n",
    "      <td style=\"text-align: center\">5</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "答えは「開催」です。以下の赤線の順でたどっていきます。\n",
    "\n",
    "\n",
    "![](https://diveintocode.gyazo.com/3abf4302fd28b9c58e9c4f86e5878661)\n",
    "\n",
    "これが決定木による推定の操作になります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "扱える特徴量\n",
    "決定木は理論上は量的変数だけでなく、カテゴリ変数も扱えます。しかし、scikit-learnの実装では量的変数のみに対応していますので、スクラッチ実装もそのように作成します。上記の例ですと「会場の種類」で「屋内と屋外」ですとカテゴリ変数ですが、「屋内かどうか」で「0と1」と量的変数にすることで扱えるようにしています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定木スクラッチ\n",
    "\n",
    "分類のための決定木のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "決定木の学習には何回まで条件分岐を繰り返すかを表す （最大の）深さ というハイパーパラメータが登場しますが、深さ1の実装を必須課題とします。深さが2以上のものはアドバンス課題とします。\n",
    "\n",
    "\n",
    "学習の仕方には様々な方法がありますが、ここではscikit-learnでも使用されている CART法 をベースとした実装を行います。この方法では学習の複雑さを減らすために、 分岐は2つに分かれるのみ になります。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchDecesionTreeClassifierDepth1クラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepth1():\n",
    "    \"\"\"\n",
    "    深さ1の決定木分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        決定木分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        決定木分類器を使いラベルを推定する\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割の条件を学習で求める\n",
    "学習によって、ノードをどういった条件で分割すると、うまく分けられるかということを求めます。\n",
    "\n",
    "\n",
    "うまく分けられていることを判定するためにノードに対してジニ不純度と情報利得という値を計算します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】不純度を求める関数\n",
    "ノード の ジニ不純度 を計算する関数を作成してください。ノード $t$に対するジニ不純度 $I(t)$は以下の数式で求まります。クラスが混じり合っているほどジニ不純度は高くなります。\n",
    "\n",
    "$$\n",
    "I(t) = 1-\\sum_{i=1}^{K}P^2(C_i|t) = 1-\\sum_{i=1}^{K}(\\frac{N_{t,i}}{N_{t,all}})^{2}\n",
    "$$\n",
    "\n",
    "$t$: ノードのインデックス\n",
    "\n",
    "\n",
    "$i$: クラスのインデックス\n",
    "\n",
    "\n",
    "$K$\n",
    " : クラスの数\n",
    "\n",
    "\n",
    "$C_{i}:$ i番目のクラス\n",
    "\n",
    "\n",
    "$P(C_{i}|t)$\n",
    " $:　t番目のノードにおけるCiの割合\n",
    "\n",
    "\n",
    "$N_{t,i}$: t番目のノードのi番目のクラスに属するサンプル数\n",
    "\n",
    "\n",
    "$N_{t,all}$ : t番目のノードのサンプルの総数\n",
    "\n",
    "\n",
    "まずは簡単な例を作り、手計算と関数の結果を比較してください。\n",
    "\n",
    "\n",
    "《例》\n",
    "\n",
    "* クラス1:サンプル数15, クラス2:サンプル数15 → ジニ不純度0.500\n",
    "* クラス1:サンプル数15, クラス2:サンプル数15, クラス3:サンプル数15 → ジニ不純度0.667\n",
    "* クラス1:サンプル数18, クラス2:サンプル数12 → ジニ不純度0.480\n",
    "* クラス1:サンプル数30, クラス2:サンプル数0 → ジニ不純度0.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini_impurity_beta(Nt):\n",
    "    gini = 1 - ((Nt[0]/sum(Nt))**2 + (Nt[1]/sum(Nt))**2)\n",
    "    return gini\n",
    "\n",
    "def gini_impurity(Nt):\n",
    "    try:\n",
    "        Nt_sum = 0\n",
    "        for i in range(len(Nt)):\n",
    "            Nt_sum += (Nt[i]/sum(Nt))**2\n",
    "        return 1 - Nt_sum  \n",
    "    except: # ゼロ除算処理\n",
    "        return 0\n",
    "\n",
    "ex_1 = [15, 15]\n",
    "ex_2 = [15, 15, 15]\n",
    "ex_3 = [18, 12]\n",
    "ex_4 = [30, 0]\n",
    "\n",
    "# gini\n",
    "gini_impurity([0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】情報利得を求める関数\n",
    "次に、ノード間の 情報利得 を計算する関数を作成してください。問題1で作成したジニ不純度 \n",
    "$I(t)$を計算する関数を呼び出して使います。情報利得$IG$は以下の数式で求まります。うまく分けられている時ほど情報利得は大きくなります。\n",
    "\n",
    "ここで分岐は2つのみであるため、分岐先を「左側のノード・右側のノード」と呼びます。\n",
    "\n",
    "$$\n",
    "IG(p) = I(p)-\\frac{N_{left,all}}{N_{p,all}}I(left)-\\frac{N_{right,all}}{N_{p,all}}I(right)\n",
    "$$\n",
    "\n",
    "$p$\n",
    " : 親ノードを示すインデックス\n",
    "\n",
    "\n",
    "$l\n",
    "e\n",
    "f\n",
    "t$\n",
    " : 左側のノードを示すインデックス\n",
    "\n",
    "\n",
    "$r\n",
    "i\n",
    "g\n",
    "h\n",
    "t$\n",
    " : 右側のノードを示すインデックス\n",
    "\n",
    "\n",
    "\n",
    "まずは簡単な例を作り、手計算と関数の結果を比較してください。\n",
    "\n",
    "\n",
    "**《例》**<br />\n",
    "左ノードクラス1:サンプル数10, 左ノードクラス2:サンプル数30, 右ノードクラス1:サンプル数20, 右ノードクラス2:サンプル数5 → 情報利得0.143\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14319526627218937"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = [10, 30]\n",
    "right = [20, 5]\n",
    "\n",
    "def gain_func(left, right):\n",
    "    n_al = sum(left) + sum(right)\n",
    "    ip_p = [left[0]+right[0], left[1]+right[1]] # ok\n",
    "    ip = gini_impurity(ip_p) # ジニ不純度 ok\n",
    "    ig_left = gini_impurity(left) # ジニ不純度 ok\n",
    "    i_left = (sum(left)/n_al)*ig_left\n",
    "    ig_right = gini_impurity(right) # ジニ不純度 ok\n",
    "    i_right = (sum(right)/n_al)*ig_right\n",
    "    igp = ip - (i_left) - (i_right) \n",
    "    return igp\n",
    "\n",
    "gain_func(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】学習\n",
    "空間の分割を行い、決定木のグラフを生成するコードを作成してください。今は深さ1の決定木なので、分割を1回だけ行います。ここでグラフを生成するとは、1回の分割の際の条件としてどの特徴量がいくつ以上の時とするかを求めるということです。\n",
    "\n",
    "\n",
    "訓練データに対して全ての組み合わせの分割を行い、その中でノード間の情報利得が最大となる分割をそのノードの分割基準として記録します。\n",
    "\n",
    "\n",
    "クラスが混ざらない不純度が0のノード、または指定された深さのノードが 葉ノード となります。葉ノードにはクラスを記録しておき、これを推定時に分類するクラスとします。クラスが混ざらない場合はそのままのクラスを記録し、混ざっている場合は多数決により決めます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《組み合わせの取り方》\n",
    "\n",
    "\n",
    "全ての組み合わせの取り方は、最も単純には各特徴量の値自体をしきい値にして分割を行う方法があります。片側の端は今回のスクラッチはこの方法で行なってください。\n",
    "\n",
    "\n",
    "他には中間の値をしきい値にする方法もあり、scikit-learnではこの方法が用いられています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《補足》\n",
    "\n",
    "\n",
    "問題2の情報利得を計算する関数はこの問題3で利用する上では、親ノードの不純度 \n",
    "I\n",
    "(\n",
    "p\n",
    ")\n",
    " は固定されるため、左右のノードの不純度の合計を計算するだけでも同じ結果が得られることになります。しかし、ここでは親ノードを考慮した情報利得を計算する実装を行なってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009072580645161255\n",
      "0.002083333333333326\n",
      "0.00035919540229886054\n",
      "0.004464285714285587\n",
      "0.01134259259259253\n",
      "0.0008012820512820901\n",
      "0.0016071428571428487\n",
      "0.010416666666666685\n",
      "0.025513285024154564\n",
      "0.01420454545454547\n",
      "0.030438311688311653\n",
      "0.05208333333333337\n",
      "0.03656376518218618\n",
      "0.024305555555555552\n",
      "0.01482843137254905\n",
      "0.03125\n",
      "0.05404411764705891\n",
      "0.0401785714285714\n",
      "0.02846659919028338\n",
      "0.018750000000000044\n",
      "0.03909632034632038\n",
      "0.027840909090909027\n",
      "0.05449879227053139\n",
      "0.041666666666666574\n",
      "0.0301785714285715\n",
      "0.020032051282051266\n",
      "0.011342592592592515\n",
      "0.004464285714285587\n",
      "0.018750000000000044\n",
      "0.018750000000000044\n",
      "0.009072580645161255\n",
      "0.025201612903225812\n",
      "0.002083333333333326\n",
      "0.00035919540229886054\n",
      "0.004464285714285754\n",
      "0.00023148148148151304\n",
      "0.0008012820512820901\n",
      "0.004464285714285712\n",
      "0.0\n",
      "0.0037741545893719697\n",
      "0.0005681818181818288\n",
      "0.006628787878787873\n",
      "0.01874999999999999\n",
      "0.03656376518218618\n",
      "0.024305555555555552\n",
      "0.01482843137254905\n",
      "0.0078125\n",
      "0.003063725490196123\n",
      "0.0004960317460318553\n",
      "0.00012651821862352808\n",
      "0.0020833333333333814\n",
      "0.006628787878787845\n",
      "0.01420454545454547\n",
      "0.025513285024154564\n",
      "0.041666666666666685\n",
      "0.0644642857142857\n",
      "0.039262820512820484\n",
      "0.01874999999999999\n",
      "0.004464285714285754\n",
      "0.017600574712643646\n",
      "0.05208333333333337\n",
      "0.025201612903225812\n",
      "X： -2.2135 最大情報利得： 0.0644642857142857 max_j： 1\n",
      "(2, 5) (18, 7)\n"
     ]
    }
   ],
   "source": [
    "max_gain = 0\n",
    "max_gain_column = None\n",
    "# 特徴量が複数に対応\n",
    "for j in range(X.shape[1]):\n",
    "    sorted_idx = np.argsort(X[:,j], axis=0) # 昇順にソートしたインデックスを格納\n",
    "    X_sorted = X[np.argsort(X[:, j])] # # 昇順にソート\n",
    "    target_sorted = target[np.argsort(X[:, j])] # yをXのソートに対応させる\n",
    "    for i in range(len(X_sorted)-1): # 候補地点:サンプル数-1\n",
    "        left_idx = np.ravel(np.where(X_sorted[:,j] > X_sorted[i,j])) # leftに対応するidx\n",
    "        right_idx = np.ravel(np.where(X_sorted[:,j]<= X_sorted[i,j])) # rightに対応するidx\n",
    "        left_y = np.ravel(target_sorted[left_idx]) # leftに対応するy\n",
    "        right_y = np.ravel(target_sorted[right_idx]) # rightに対応するy\n",
    "        left = len(left_y[left_y==0]), len(left_y[left_y==1]) # leftの0,1ラベルのリスト\n",
    "        right = len(right_y[right_y==0]), len(right_y[right_y==1]) # rightの0,1ラベルのリスト\n",
    "        print(gain_func(left, right))\n",
    "        if gain_func(left, right) > max_gain:\n",
    "            max_gain = gain_func(left, right)\n",
    "            max_idx = i\n",
    "            max_gain_column = j\n",
    "        else:\n",
    "            pass\n",
    "print('X：', X[max_idx, max_gain_column], '最大情報利得：', max_gain, 'max_j：', max_gain_column)    \n",
    "left_gained_idx = np.ravel(np.where(X_sorted[:, max_gain_column] > X_sorted[max_idx, max_gain_column])) # max_gainのleftに対応するidx\n",
    "right_gained_idx = np.ravel(np.where(X_sorted[:, max_gain_column]<= X_sorted[max_idx, max_gain_column])) # max_gainのrightに対応するidx\n",
    "left_gained_y = np.ravel(target_sorted[left_gained_idx]) # max_gainのleftに対応するy\n",
    "right_gained_y = np.ravel(target_sorted[right_gained_idx]) # max_gainのrightに対応するy\n",
    "left_gained = len(left_gained_y[left_gained_y==0]), len(left_gained_y[left_gained_y==1]) # leftの0,1ラベルのリスト\n",
    "right_gained = len(right_gained_y[right_gained_y==0]), len(right_gained_y[right_gained_y==1]) # rightの0,1ラベルのリスト\n",
    "print(left_gained, right_gained)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】推定\n",
    "推定する仕組みを実装してください。ScratchDecesionTreeClassifierDepth1クラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "\n",
    "入力されたデータの値を学習した条件で判定していき、どの葉ノードに到達するかを見ます。葉ノードにはクラスが記録されているので、これが推定値となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    \"\"\"\n",
    "    決定木分類器を使いラベルを推定する\n",
    "    \"\"\"\n",
    "    if left_gained[0] > left_gained[1]:\n",
    "        pred = np.where(X[:,max_gain_column] > max_gain, 0, 1)\n",
    "    else:\n",
    "        pred = np.where(X[:,max_gain_column] <= max_gain, 1, 0)\n",
    "    return pred\n",
    "\n",
    "y_pred = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [1 0 0 1 0 0 0 1]\n",
      "y_test: [0 0 0 1 0 0 1 1]\n",
      "正解率： 0.75\n"
     ]
    }
   ],
   "source": [
    "print('y_pred:', y_pred,)\n",
    "print('y_test:',y_test)\n",
    "print('正解率：', np.sum(y_pred==y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したシンプルデータセット2の2値分類に対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n",
    "\n",
    "\n",
    "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラス構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepth1():\n",
    "    \"\"\"\n",
    "    深さ1の決定木分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "\n",
    "\n",
    "# ジニ不純度を求める関数\n",
    "    def gini_impurity(self, Nt):\n",
    "        try:\n",
    "            Nt_sum = 0\n",
    "            for i in range(len(Nt)):\n",
    "                Nt_sum += (Nt[i]/sum(Nt))**2\n",
    "            return 1 - Nt_sum  \n",
    "        except: # ゼロ除算処理\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    def gain_func(self, left, right):\n",
    "        n_al = sum(left) + sum(right)\n",
    "        ip_p = [left[0]+right[0], left[1]+right[1]] # ok\n",
    "        ip = gini_impurity(ip_p) # ジニ不純度 ok\n",
    "        ig_left = self.gini_impurity(left) # ジニ不純度 ok\n",
    "        i_left = (sum(left)/n_al)*ig_left\n",
    "        ig_right = gini_impurity(right) # ジニ不純度 ok\n",
    "        i_right = (sum(right)/n_al)*ig_right\n",
    "        igp = ip - (i_left) - (i_right) \n",
    "        return igp  \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        決定木分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        \"\"\"\n",
    "        self.max_gain = 0\n",
    "        self.max_gain_column = None\n",
    "        # 特徴量が複数に対応\n",
    "        for j in range(X.shape[1]):\n",
    "            X_sorted = X[np.argsort(X[:, j])] # # Xの値をソート（昇順）\n",
    "            y_sorted = y[np.argsort(X[:, j])] # yをXのソートに対応させる\n",
    "            for i in range(len(X)-1): # 候補地点:サンプル数-1\n",
    "                left_idx = np.ravel(np.where(X_sorted[:,j] > X_sorted[i,j])) # leftに対応するidx\n",
    "                right_idx = np.ravel(np.where(X_sorted[:,j]<= X_sorted[i,j])) # rightに対応するidx\n",
    "                left_y = np.ravel(target_sorted[left_idx]) # leftに対応するy\n",
    "                right_y = np.ravel(target_sorted[right_idx]) # rightに対応するy\n",
    "                left = len(left_y[left_y==0]), len(left_y[left_y==1]) # leftの0,1ラベルのリスト\n",
    "                right = len(right_y[right_y==0]), len(right_y[right_y==1]) # rightの0,1ラベルのリスト\n",
    "                if self.gain_func(left, right) > self.max_gain:\n",
    "                    self.max_gain = self.gain_func(left, right)\n",
    "                    self.max_idx = i\n",
    "                    self.max_gain_column = j\n",
    "                else:\n",
    "                    pass\n",
    "        print('X：', X[max_idx, max_gain_column], '最大情報利得：', max_gain, 'max_j：', max_gain_column)    \n",
    "        left_gained_idx = np.ravel(np.where(X_sorted[:, max_gain_column] > X_sorted[max_idx, max_gain_column])) # max_gainのleftに対応するidx\n",
    "        right_gained_idx = np.ravel(np.where(X_sorted[:, max_gain_column]<= X_sorted[max_idx, max_gain_column])) # max_gainのrightに対応するidx\n",
    "        left_gained_y = np.ravel(target_sorted[left_gained_idx]) # max_gainのleftに対応するy\n",
    "        right_gained_y = np.ravel(target_sorted[right_gained_idx]) # max_gainのrightに対応するy\n",
    "        self.left_gained = len(left_gained_y[left_gained_y==0]), len(left_gained_y[left_gained_y==1]) # leftの0,1ラベルのリスト\n",
    "        right_gained = len(right_gained_y[right_gained_y==0]), len(right_gained_y[right_gained_y==1]) # rightの0,1ラベルのリスト        \n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        決定木分類器を使いラベルを推定する\n",
    "        \"\"\"\n",
    "        if self.left_gained[0] > self.left_gained[1]:\n",
    "            self.pred = np.where(X[:,max_gain_column] > max_gain, 0, 1)\n",
    "        else:\n",
    "            self.pred = np.where(X[:,max_gain_column] <= max_gain, 1, 0)\n",
    "        return self.pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X： -2.2135 最大情報利得： 0.0644642857142857 max_j： 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ScratchDecesionTreeClassifierDepth1()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.73      0.73      0.73         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】決定領域の可視化\n",
    "決定領域を可視化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a219e7c10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "plot_decision_regions(X_test, y_test, model,res=0.02, legend=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.model_selection import KFold\n",
    ">>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    ">>> y = np.array([1, 2, 3, 4])\n",
    ">>> kf = KFold(n_splits=2)\n",
    ">>> kf.get_n_splits(X)\n",
    "2\n",
    ">>> print(kf)\n",
    "KFold(n_splits=2, random_state=None, shuffle=False)\n",
    ">>> for train_index, test_index in kf.split(X):\n",
    "...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "...     X_train, X_test = X[train_index], X[test_index]\n",
    "...     y_train, y_test = y[train_index], y[test_index]\n",
    "TRAIN: [2 3] TEST: [0 1]\n",
    "TRAIN: [0 1] TEST: [2 3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
