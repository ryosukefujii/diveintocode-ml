{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープニューラルネットワークスクラッチ\n",
    "\n",
    "前回は3層のニューラルネットワークを作成しましたが、今回はこれを任意の層数に拡張しやすいものに書き換えていきます。その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。\n",
    "\n",
    "\n",
    "このようなスクラッチを行うことで、今後各種フレームワークを利用していくにあたり、内部の動きが想像できることを目指します。\n",
    "\n",
    "\n",
    "名前は新しくScratchDeepNeuralNetrowkClassifierクラスとしてください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 層などのクラス化\n",
    "クラスにまとめて行くことで、構成を変更しやすい実装にしていきます。\n",
    "\n",
    "\n",
    "手を加える箇所\n",
    "\n",
    "\n",
    "* 層の数\n",
    "* 層の種類（今後畳み込み層など他のタイプの層が登場する）\n",
    "* 活性化関数の種類\n",
    "* 重みやバイアスの初期化方法\n",
    "* 最適化手法\n",
    "\n",
    "そのために、全結合層、各種活性化関数、重みやバイアスの初期化、最適化手法それぞれのクラスを作成します。\n",
    "\n",
    "\n",
    "実装方法は自由ですが、簡単な例を紹介します。サンプルコード1のように全結合層と活性化関数のインスタンスを作成し、サンプルコード2,3のようにして使用します。それぞれのクラスについてはこのあと解説します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《サンプルコード1》\n",
    "\n",
    "ScratchDeepNeuralNetrowkClassifierのfitメソッド内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.sigma : ガウス分布の標準偏差\n",
    "# self.lr : 学習率\n",
    "# self.n_nodes1 : 1層目のノード数\n",
    "# self.n_nodes2 : 2層目のノード数\n",
    "# self.n_output : 出力層のノード数\n",
    "\n",
    "# optimizer = SGD(self.lr)\n",
    "# self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "# self.activation1 = Tanh()\n",
    "# self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "# self.activation2 = Tanh()\n",
    "# self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "# self.activation3 = Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《サンプルコード2》\n",
    "\n",
    "\n",
    "イテレーションごとのフォワード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1 = self.FC1.forward(X)\n",
    "# Z1 = self.activation1.forward(A1)\n",
    "# A2 = self.FC2.forward(Z1)\n",
    "# Z2 = self.activation2.forward(A2)\n",
    "# A3 = self.FC3.forward(Z2)\n",
    "# Z3 = self.activation3.forward(A3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《サンプルコード3》\n",
    "イテレーションごとのバックワード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dA3 = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "# dZ2 = self.FC3.backward(dA3)\n",
    "# dA2 = self.activation2.backward(dZ2)\n",
    "# dZ1 = self.FC2.backward(dA2)\n",
    "# dA1 = self.activation1.backward(dZ1)\n",
    "# dZ0 = self.FC1.backward(dA1) # dZ0は使用しない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "\n",
    "また、引数として自身のインスタンス`self`を渡すこともできます。これを利用して`self.optimizer.update(self)`という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《雛形》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FC:\n",
    "#     \"\"\"\n",
    "#     ノード数n_nodes1からn_nodes2への全結合層\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     n_nodes1 : int\n",
    "#       前の層のノード数\n",
    "#     n_nodes2 : int\n",
    "#       後の層のノード数\n",
    "#     initializer : 初期化方法のインスタンス\n",
    "#     optimizer : 最適化手法のインスタンス\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "#         self.optimizer = optimizer\n",
    "#         # 初期化\n",
    "#         # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "#         pass\n",
    "#     def forward(self, X):\n",
    "#         \"\"\"\n",
    "#         フォワード\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "#             入力\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "#             出力\n",
    "#         \"\"\"        \n",
    "#         pass\n",
    "#         return A\n",
    "#     def backward(self, dA):\n",
    "#         \"\"\"\n",
    "#         バックワード\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "#             後ろから流れてきた勾配\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "#             前に流す勾配\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         # 更新\n",
    "#         self = self.optimizer.update(self)\n",
    "#         return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】解答（FC）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "#         self.n_nodes1 = n_nodes1\n",
    "#         self.n_nodes2 = n_nodes2\n",
    "\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "#         self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "        self.W = self.initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = self.initializer.B(n_nodes2)\n",
    "        self.H_W = 0\n",
    "        self.H_B = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.Z = x # 前のレイヤーのZを取得\n",
    "        A = x@self.W + self.B\n",
    "        \n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "\n",
    "        dZ = dA@self.W.T # このレイヤーのW\n",
    "\n",
    "        # 更新\n",
    "        self.B_dash = np.mean(dA, axis=0)\n",
    "        self.W_dash = self.Z.T@dA # 前のレイヤーのZ\n",
    "        self = self.optimizer.update(self) # この引数のselfはこの\"class FCのインスタンス自体\"を取得している。\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《雛形》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleInitializer:\n",
    "#     \"\"\"\n",
    "#     ガウス分布によるシンプルな初期化\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     sigma : float\n",
    "#       ガウス分布の標準偏差\n",
    "#     \"\"\"\n",
    "#     def __init__(self, sigma):\n",
    "#         self.sigma = sigma\n",
    "#     def W(self, n_nodes1, n_nodes2):\n",
    "#         \"\"\"\n",
    "#         重みの初期化\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         n_nodes1 : int\n",
    "#           前の層のノード数\n",
    "#         n_nodes2 : int\n",
    "#           後の層のノード数\n",
    "\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         W :\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         return W\n",
    "#     def B(self, n_nodes2):\n",
    "#         \"\"\"\n",
    "#         バイアスの初期化\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         n_nodes2 : int\n",
    "#           後の層のノード数\n",
    "\n",
    "#         Returns\n",
    "#         ----------\n",
    "#         B :\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "#         return BaseException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】解答（SimpleInitializer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)       \n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときに`self.optimizer.update(self)`のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 雛形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SGD:\n",
    "#     \"\"\"\n",
    "#     確率的勾配降下法\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     lr : 学習率\n",
    "#     \"\"\"\n",
    "#     def __init__(self, lr):\n",
    "#         self.lr = lr\n",
    "#     def update(self, layer):\n",
    "#         \"\"\"\n",
    "#         ある層の重みやバイアスの更新\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         layer : 更新前の層のインスタンス\n",
    "#         \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】解答（SGD）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        # layerの引数は\"class FCのインスタンス自体\"を取得している。\n",
    "\n",
    "        layer.B -= self.lr*layer.B_dash # B更新\n",
    "        layer.W -= self.lr*layer.W_dash # W更新\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】解答（活性化関数のクラス化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def cross_entropy_func(self, x, y):\n",
    "        li = np.empty(len(x))\n",
    "        for i in range(len(x)):\n",
    "            lj = np.empty(10) # 10 = self.n_output, 最終的に変数にする\n",
    "            for j in range(10): # 10 = self.n_output, 最終的に変数にする\n",
    "                lj[j] = y[i,j]*np.log(x[i,j])\n",
    "            li[i] = sum(lj)\n",
    "        self.l = sum(li)/-10 # 10 = self.n_output, 最終的に変数にする\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_max = np.max(x, axis=1)\n",
    "        exp_x = np.exp(x - x_max.reshape(-1, 1))\n",
    "        sum_exp_x = np.sum(exp_x, axis=1).reshape(-1, 1)  \n",
    "        return exp_x/sum_exp_x\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        self.cross_entropy_func(x, y)\n",
    "        return x - y\n",
    "\n",
    "\n",
    "      \n",
    "class Tanh:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.A = x # backwardの引数のためのAを保管\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*(1 - np.tanh(self.A)**2)\n",
    "\n",
    "class Sigmoid:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.A = x # backwardの引数のためのAを保管\n",
    "        return 1.0 / (1.0 + np.exp(-x)) \n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*(1 - np.tanh(self.A)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発展的要素\n",
    "活性化関数や重みの初期値、最適化手法に関してこれまで見てきた以外のものを実装していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=42):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScratchDeepNeuralNetrowkClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=None, batch_size=20, a=0.01, n_epoch=5):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = a\n",
    "        self.n_epoch = n_epoch\n",
    "\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # self.sigma : ガウス分布の標準偏差\n",
    "        # self.lr : 学習率\n",
    "        self.n_features = 784\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 = 200\n",
    "        self.n_output = 10\n",
    "        self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "\n",
    "        # self.n_nodes1 : 1層目のノード数\n",
    "        # self.n_nodes2 : 2層目のノード数\n",
    "        # self.n_output : 出力層のノード数\n",
    "        \n",
    "# fitメソッド内        \n",
    "        optimizer = SGD(self.lr)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation1 = Tanh()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation2 = Tanh()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation3 = Softmax()\n",
    "        \n",
    "        get_mini_batch = GetMiniBatch(X, y, batch_size = self.batch_size)\n",
    "        self.l_list = np.empty(self.n_epoch)\n",
    "        self.l_val_list = np.empty(self.n_epoch)\n",
    "        self.cnt = 0\n",
    "        self.cnt_list = []\n",
    "        for i in range(self.n_epoch):\n",
    "            for X, y in get_mini_batch:        \n",
    "        \n",
    "        \n",
    "# イテレーションごとのフォワード        \n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "\n",
    "# イテレーションごとのバックワード\n",
    "                dA3 = self.activation3.backward(Z3, y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない        \n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        \n",
    "        return np.argmax(Z3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "\n",
    "ReLUは以下の数式です。\n",
    "\n",
    "$$\n",
    "% <![CDATA[\n",
    "f(x) = ReLU(x) = \\begin{cases}\n",
    "x  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$$\n",
    "\n",
    "$x$\n",
    " : ある特徴量。スカラー\n",
    "\n",
    "\n",
    "実装上は`np.maximum`を使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "\n",
    "[numpy.maximum — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.maximum.html)\n",
    "\n",
    "\n",
    "一方、バックプロパゲーションのための \n",
    "$x$に関する $f(x)$の微分は以下のようになります。\n",
    "\n",
    "$$\n",
    "% <![CDATA[\n",
    "\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}\n",
    "1  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$$\n",
    "\n",
    "数学的には微分可能ではないですが、 \n",
    "$x\n",
    "=\n",
    "0$\n",
    " のとき \n",
    "$0$\n",
    " とすることで対応しています。\n",
    "\n",
    "\n",
    "フォワード時の \n",
    "$x$\n",
    " の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,-1])\n",
    "np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】解答（ReLU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.F = np.where(x > 0, 1, 0) # backwardの引数のためのAを保管\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def backward(self, x):\n",
    "        return x*self.F\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは **Xavierの初期値** （またはGlorotの初期値）、ReLUのときは **Heの初期値** が使われます。\n",
    "\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavierの初期値\n",
    "Xavierの初期値における標準偏差 \n",
    "$σ$\n",
    " は次の式で求められます。\n",
    " \n",
    "$$\n",
    "\\sigma = \\frac{1}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "$n$\n",
    " : 前の層のノード数\n",
    "\n",
    "\n",
    "**《論文》**\n",
    "\n",
    "\n",
    "[Glorot, X., & Bengio, Y. (n.d.). Understanding the difficulty of training deep feedforward neural networks.](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】解答（Xavier）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xavier:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Xavierの初期値\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.sigma = 1/np.sqrt(n_nodes1) # self.batch_sizeかも\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)       \n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heの初期値\n",
    "Heの初期値における標準偏差 \n",
    "$σ$\n",
    " は次の式で求められます。\n",
    " \n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{2}{n}}\n",
    "$$\n",
    "\n",
    "$n$\n",
    " : 前の層のノード数\n",
    "\n",
    "\n",
    "**《論文》**\n",
    "\n",
    "\n",
    "[He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.](https://arxiv.org/pdf/1502.01852.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】解答（He）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class He:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Xavierの初期値\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.sigma = np.sqrt(2/n_nodes1) \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)       \n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である **AdaGrad** のクラスを作成してください。\n",
    "\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。\n",
    "\n",
    "$$\n",
    "W_i^{\\prime} = W_i - \\alpha E(\\frac{\\partial L}{\\partial W_i}) \\\\B_i^{\\prime} = B_i - \\alpha E(\\frac{\\partial L}{\\partial B_i})\n",
    "$$\n",
    "\n",
    "$α$: 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}: W_i$に関する損失 Lの勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}: B_i$に関する損失 Lの勾配\n",
    "\n",
    "\n",
    "$E(): $ミニバッチ方向にベクトルの平均を計算\n",
    "\n",
    "\n",
    "続いて、AdaGradです。バイアスの数式は省略しますが、重みと同様のことをします。\n",
    "\n",
    "\n",
    "更新された分だけその重みに対する学習率を徐々に下げていきます。イテレーションごとの勾配の二乗和 \n",
    "H\n",
    " を保存しておき、その分だけ学習率を小さくします。\n",
    "\n",
    "\n",
    "学習率は重み一つひとつに対して異なることになります。\n",
    "\n",
    "$$\n",
    "H_i^{\\prime}  = H_i+E(\\frac{\\partial L}{\\partial W_i})×E(\\frac{\\partial L}{\\partial W_i})\\\\W_i^{\\prime} = W_i - \\alpha \\frac{1}{\\sqrt{H_i^{\\prime} }} E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "$$\n",
    "\n",
    "$H_i: i$層目に関して、前のイテレーションまでの勾配の二乗和（初期値は0）\n",
    "\n",
    "$H′_i$: $更新した H_i$\n",
    "\n",
    "《論文》\n",
    "\n",
    "\n",
    "[Duchi JDUCHI, J., & Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization * Elad Hazan. Journal of Machine Learning Research (Vol. 12).](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】解答（AdaGrad）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        # layerの引数は\"class FCのインスタンス自体\"を取得している。\n",
    "        H_B =layer.H_B + layer.B_dash**2\n",
    "        H_W =layer.H_W + layer.W_dash**2 \n",
    "        layer.B -= self.lr/np.sqrt(H_B + 0.1)*layer.B_dash # B更新\n",
    "        layer.W -= self.lr/np.sqrt(H_W + 0.1)*layer.W_dash # W更新\n",
    "        layer.H_B = H_B\n",
    "        layer.H_W = H_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ScratchDeepNeuralNetrowkClassifier()\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier_2:\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=None, batch_size=20, a=0.01, n_epoch=5):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = a\n",
    "        self.n_epoch = n_epoch\n",
    "\n",
    "    def cross_entropy_func(self, X, y):\n",
    "        li = np.empty(len(X))   \n",
    "        for i in range(len(X)):\n",
    "            lj = np.empty(self.n_output)\n",
    "            for j in range(self.n_output):\n",
    "                lj[j] = y[i,j]*np.log(X[i,j])\n",
    "            li[i] = sum(lj)\n",
    "        self.l = sum(li)/-self.n_output\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # self.sigma : ガウス分布の標準偏差\n",
    "        # self.lr : 学習率\n",
    "        self.n_features = 784\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 = 200\n",
    "        self.n_output = 10\n",
    "        self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "\n",
    "        # self.n_nodes1 : 1層目のノード数\n",
    "        # self.n_nodes2 : 2層目のノード数\n",
    "        # self.n_output : 出力層のノード数\n",
    "        \n",
    "# fitメソッド内        \n",
    "        optimizer = AdaGrad(self.lr)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, Xavier(self.n_features), optimizer)\n",
    "        self.activation1 = Tanh()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, Xavier(self.n_nodes1), optimizer)\n",
    "        self.activation2 = Tanh()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, Xavier(self.n_nodes2), optimizer)\n",
    "        self.activation3 = Softmax()\n",
    "# ミニバッチ        \n",
    "        get_mini_batch = GetMiniBatch(X, y, batch_size = self.batch_size)\n",
    "        self.l_list = np.empty(self.n_epoch)\n",
    "        self.l_val_list = np.empty(self.n_epoch)\n",
    "        self.cnt = 0\n",
    "        self.cnt_list = []\n",
    "        for i in range(self.n_epoch):\n",
    "            for X_mini, y_mini in get_mini_batch:             \n",
    "# イテレーションごとのフォワード        \n",
    "                A1 = self.FC1.forward(X_mini)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "# イテレーションごとのバックワード\n",
    "                dA3 = self.activation3.backward(Z3, y_mini) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない        \n",
    "# 評価（クロスエントロピー誤差）\n",
    "            # X, y\n",
    "            A1 = self.FC1.forward(X)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            A2 = self.FC2.forward(Z1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            A3 = self.FC3.forward(Z2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            self.cross_entropy_func(Z3, y)\n",
    "            self.l_list[i] = self.l\n",
    "            self.cnt += 1\n",
    "            self.cnt_list.append(self.cnt)    \n",
    "            # X_val, y_val\n",
    "            A1 = self.FC1.forward(X_val)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            A2 = self.FC2.forward(Z1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            A3 = self.FC3.forward(Z2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            self.cross_entropy_func(Z3, y_val)\n",
    "            self.l_val_list[i] = self.l                \n",
    "                \n",
    "                \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        \n",
    "        return np.argmax(Z3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = ScratchDeepNeuralNetrowkClassifier_2()\n",
    "model_2.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795833333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred_2 = model_2.predict(X_train)\n",
    "y_true_2 = np.argmax(y_train, axis=1)\n",
    "\n",
    "print(accuracy_score(y_true_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9687\n"
     ]
    }
   ],
   "source": [
    "y_pred_2 = model_2.predict(X_test)\n",
    "y_true_2 = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(accuracy_score(y_true_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x146f9f7d0>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set()\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(model_2.cnt_list, model_2.l_list, label='train')\n",
    "plt.plot(model_2.cnt_list, model_2.l_val_list, label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
