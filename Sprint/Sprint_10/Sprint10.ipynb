{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/FUZZY/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb # for debug\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1次元の畳み込みニューラルネットワークスクラッチ\n",
    "\n",
    "**畳み込みニューラルネットワーク（CNN）** のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "このSprintでは1次元の **畳み込み層** を作成し、畳み込みの基礎を理解することを目指します。次のSprintでは2次元畳み込み層とプーリング層を作成することで、一般的に画像に対して利用されるCNNを完成させます。\n",
    "\n",
    "\n",
    "クラスの名前はScratch1dCNNClassifierとしてください。クラスの構造などは前のSprintで作成したScratchDeepNeuralNetrowkClassifierを参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1次元畳み込み層とは\n",
    "CNNでは画像に対しての2次元畳み込み層が定番ですが、ここでは理解しやすくするためにまずは1次元畳み込み層を実装します。1次元畳み込みは実用上は自然言語や波形データなどの 系列データ で使われることが多いです。\n",
    "\n",
    "\n",
    "畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまではフレームワークで一般的に用意されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの用意\n",
    "検証には引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$\n",
    "\n",
    "$a_i$\n",
    " : 出力される配列のi番目の値\n",
    "\n",
    "\n",
    "$F$\n",
    " : フィルタのサイズ\n",
    "\n",
    "\n",
    "$x(_{i+s})$\n",
    " : 入力の配列の(i+s)番目の値\n",
    "\n",
    "\n",
    "$w_s$\n",
    " : 重みの配列のs番目の値\n",
    "\n",
    "\n",
    "$b$\n",
    " : バイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "$$\n",
    "w_s^{\\prime} = w_s - \\alpha \\frac{\\partial L}{\\partial w_s} \\\\\n",
    "b^{\\prime} = b - \\alpha \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "$α$\n",
    "  : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s}$: $w_s$\n",
    "に関する損失 $L$の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b}$\n",
    " : \n",
    "$b$\n",
    " に関する損失 \n",
    "$L$\n",
    " の勾配\n",
    "\n",
    "\n",
    "勾配 \n",
    "$\\frac{\\partial L}{\\partial w_s}$や $\\frac{\\partial L}{\\partial b}$ を求めるためのバックプロパゲーションの数式が以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}\\\\\n",
    "\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}\n",
    "$$\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$\n",
    " : 勾配の配列のi番目の値\n",
    "\n",
    "\n",
    "$N\n",
    "_{o\n",
    "u\n",
    "t}$\n",
    " : 出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s\n",
    "$$\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j}$\n",
    " : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "\n",
    "ただし、 \n",
    "$j−s<0$\n",
    " または \n",
    "$j−s>N_{out}−1$\n",
    " のとき \n",
    "$\\frac{\\partial L}{\\partial a_{(j-s)}} =0$\n",
    " です。\n",
    "\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, W, B):\n",
    "        self.W = W\n",
    "        self.B = B\n",
    "        self.lr = 1\n",
    "               \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.N_in = len(x) # 入力のサイズ（特徴量の数）\n",
    "        self.P = 0 # Padding\n",
    "        self.F = len(self.W) # フィルタのサイズ\n",
    "        self.S = 1 # stride\n",
    "        self.N_out = int((self.N_in + 2* self.P - self.F)/self.S + 1) # 𝑁𝑜𝑢𝑡  : 出力のサイズ（特徴量の数\n",
    "        \n",
    "        self.Z = x # 今回必要？\n",
    "        self.A = np.empty(self.N_out)\n",
    "        for i in range(self.F-1):\n",
    "            self.A[i] = sum(x[i:i + self.F]*self.W)+self.B\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = dA  # 今回必要？\n",
    "                \n",
    "        dZ = np.empty(self.N_in)\n",
    "        for j in range(self.N_in):\n",
    "            dZ_list = np.empty(self.F)\n",
    "            for i in range(self.F):\n",
    "                val = j - i\n",
    "                if val < 0 or val > self.N_out -1:\n",
    "                    dZ_list[i] = 0\n",
    "                else:\n",
    "                    dZ_list[i] = dA[val]*self.W[i]\n",
    "                dZ[j] = sum(dZ_list) \n",
    "        self.dZ = dZ\n",
    "        return dZ\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.forward(X)\n",
    "        dA = np.array([10, 20])\n",
    "        self.backward(dA)\n",
    "        # w 更新\n",
    "        new_W = np.empty(self.F)\n",
    "        for i in range(self.F):\n",
    "            new_W[i] = sum(self.X[i:i+self.N_out]*dA)\n",
    "        self.W = new_W\n",
    "        # b 更新  \n",
    "        new_B = sum(dA)\n",
    "        self.B = new_B \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        self.forward_propagation_func(X)\n",
    "        return np.argmax(self.z3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{out} =  \\frac{N_{in}+2P-F}{S} + 1\\\\\n",
    "$$\n",
    "\n",
    "$N\n",
    "_{o\n",
    "u\n",
    "t}$\n",
    " : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{\n",
    "i\n",
    "n}$\n",
    " : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$\n",
    " : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$\n",
    " : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$\n",
    " : ストライドのサイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dA = np.array([10, 20]) # バックプロバゲーションここから始まる\n",
    "\n",
    "# # w 更新\n",
    "# w_new = np.empty(F)\n",
    "# for i in range(F):\n",
    "#     w_new[i] = sum(x[i:i+N_out]*dA)\n",
    "\n",
    "# w_new\n",
    "# # b 更新  \n",
    "# b_new = sum(dA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # delta_b = np.array([30])\n",
    "# # delta_w = np.array([50, 80, 110])\n",
    "# # delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_in = len(x) # 入力のサイズ（特徴量の数）\n",
    "# P = 0 # Padding\n",
    "# F = len(w) # フィルタのサイズ\n",
    "# S = 1 # stride\n",
    "# N_out = int((N_in + 2* P - F)/S + 1)\n",
    "# N_out # 𝑁𝑜𝑢𝑡  : 出力のサイズ（特徴量の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bk-proba\n",
    "# dZ = np.empty(N_in)\n",
    "# for j in range(N_in):\n",
    "#     dZ_list = np.empty(F)\n",
    "#     for i in range(F):\n",
    "#         val = j - i\n",
    "#         print(val)\n",
    "#         if val < 0 or val > N_out -1:\n",
    "#             dZ_list[i] = 0\n",
    "#         else:\n",
    "#             dZ_list[i] = dA[val]*w[i]\n",
    "#         dZ[j] = sum(dZ_list)\n",
    "# dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "\n",
    "入力$x$、重み$w$、バイアス$b$を次のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードプロパゲーションをすると出力は次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([35, 50])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にバックプロパゲーションを考えます。誤差は次のようであったとします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_a = np.array([10, 20]) # バックプロバゲーションここから始まる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バックプロパゲーションをすると次のような値になります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [35. 50.]\n",
      "delta_b: 30\n",
      "delta_w: [ 50.  80. 110.]\n",
      "delta_x: [ 30. 110. 170. 140.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "\n",
    "sample = SimpleConv1d(w, b)\n",
    "y = np.array([30, 110, 170, 140]) # fit用の仮値\n",
    "sample.fit(x, y)\n",
    "print('a:', sample.A)\n",
    "print('delta_b:', sample.B)\n",
    "print('delta_w:', sample.W)\n",
    "print('delta_x:', sample.dZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # fw-proba\n",
    "# A = np.empty(N_out)\n",
    "# for i in range(F-1):\n",
    "#     A[i] = sum(x[i:i + F]*w)+b\n",
    "# A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装上の工夫\n",
    "畳み込みを実装する場合は、まずはfor文を重ねていく形で構いません。しかし、できるだけ計算は効率化させたいため、以下の式を一度に計算する方法を考えることにします。\n",
    "\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$\n",
    "\n",
    "バイアス項は単純な足し算のため、重みの部分を見ます。\n",
    "\n",
    "$$\n",
    "\\sum_{s=0}^{F-1}x_{(i+s)}w_s\n",
    "$$\n",
    "\n",
    "これは、xの一部を取り出した配列とwの配列の内積です。具体的な状況を考えると、以下のようなコードで計算できます。この例では流れを分かりやすくするために、各要素同士でアダマール積を計算してから合計を計算しています。これは結果的に内積と同様です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35., 50.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "a = np.empty((2, 3))\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "a = a.sum(axis=1)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarrayは配列を使ったインデックス指定ができることを利用した方法です。\n",
    "\n",
    "\n",
    "また、二次元配列を使えば一次元配列から二次元配列が取り出せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このこととブロードキャストなどをうまく組み合わせることで、一度にまとめて計算することも可能です。\n",
    "\n",
    "\n",
    "畳み込みの計算方法に正解はないので、自分なりに効率化していってください。\n",
    "\n",
    "\n",
    "**《参考》**\n",
    "\n",
    "\n",
    "以下のページのInteger array indexingの部分がこの方法についての記述です。\n",
    "\n",
    "\n",
    "[Indexing — NumPy v1.17 Manual](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。\n",
    "\n",
    "\n",
    "例えば以下のようなx, w, bがあった場合は、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x[:,0:2], axis=0)\n",
    "np.sum(x[:,0:3]*w[0,:,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力は次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力が2チャンネル、出力が3チャンネルの例です。計算グラフを書いた上で、バックプロパゲーションも手計算で考えてみましょう。計算グラフの中には和と積しか登場しないので、微分を新たに考える必要はありません。\n",
    "\n",
    "\n",
    "**《補足》**\n",
    "\n",
    "\n",
    "チャンネル数を加える場合、配列をどういう順番にするかという問題があります。(`バッチサイズ`、`チャンネル数`、`特徴量数`)または(`バッチサイズ`、`特徴量数`、`チャンネル数`)が一般的で、ライブラリによって順番は異なっています。（切り替えて使用できるものもあります）\n",
    "\n",
    "\n",
    "今回のスクラッチでは自身の実装上どちらが効率的かを考えて選んでください。上記の例ではバッチサイズは考えておらず、(`チャンネル数`、`特徴量数`)です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_:　\n",
      " [[1 2 3 4]\n",
      " [2 3 4 5]]\n",
      "x_shape:　\n",
      " (2, 4)\n",
      "---------\n",
      "w_:　\n",
      " [[[1 1 2]\n",
      "  [2 1 1]]\n",
      "\n",
      " [[2 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]]]\n",
      "w_shape:　\n",
      " (3, 2, 3)\n",
      "---------\n",
      "b_:　\n",
      " [1 2 3]\n",
      "b_shape:　\n",
      " (3,)\n",
      "---------\n",
      "out_:　\n",
      " [[21 29]\n",
      " [18 25]\n",
      " [18 24]]\n",
      "out_shape:　\n",
      " (3, 2)\n",
      "---------\n",
      "loss_:　\n",
      " [[ 9 11]\n",
      " [32 35]\n",
      " [52 56]]\n",
      "loss_shape:　\n",
      " (3, 2)\n",
      "---------\n",
      "x_delta:　\n",
      " [[125 230 204 113]\n",
      " [102 206 195 102]]\n",
      "x_delta_shape:　\n",
      " (2, 4)\n",
      "---------\n",
      "w_delta:　\n",
      " [[[ 31  51  71]\n",
      "  [ 51  71  91]]\n",
      "\n",
      " [[102 169 236]\n",
      "  [169 236 303]]\n",
      "\n",
      " [[164 272 380]\n",
      "  [272 380 488]]]\n",
      "w_delta_shape:　\n",
      " (3, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "## フォワードプロパゲーション・バックプロパゲーションの確認用トイデータ\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_ = np.array([[1,2,3,4],\n",
    "               [2,3,4,5]])\n",
    "\n",
    "\n",
    "w_ = np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "\n",
    "\n",
    "b_ = np.array([1,2,3])\n",
    "\n",
    "# フォワードの出力\n",
    "out_ = np.array([[21,29],\n",
    "                [18,25],\n",
    "                [18,24]])\n",
    "\n",
    "\n",
    "loss_ = np.array([[9,11],\n",
    "                [32,35],\n",
    "                [52,56]])\n",
    "\n",
    "\n",
    "# バックワードの勾配\n",
    "x_delta = np.array([[125,230,204,113],\n",
    "                    [102,206,195,102]])\n",
    "\n",
    "\n",
    "w_delta = np.array([[[31,51,71],[51,71,91]],\n",
    "                    [[102,169,236],[169,236,303]],\n",
    "                    [[164,272,380],[272,380,488]]])\n",
    "\n",
    "\n",
    "print('x_:　\\n',x_)\n",
    "print('x_shape:　\\n',x_.shape)\n",
    "print('---------')\n",
    "print('w_:　\\n',w_)\n",
    "print('w_shape:　\\n',w_.shape)\n",
    "print('---------')\n",
    "print('b_:　\\n',b_)\n",
    "print('b_shape:　\\n',b_.shape)\n",
    "print('---------')\n",
    "print('out_:　\\n',out_)\n",
    "print('out_shape:　\\n',out_.shape)\n",
    "print('---------')\n",
    "print('loss_:　\\n',loss_)\n",
    "print('loss_shape:　\\n',loss_.shape)\n",
    "print('---------')\n",
    "print('x_delta:　\\n',x_delta)\n",
    "print('x_delta_shape:　\\n',x_delta.shape)\n",
    "print('---------')\n",
    "print('w_delta:　\\n',w_delta)\n",
    "print('w_delta_shape:　\\n',w_delta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 31.,  51.,  71.],\n",
       "        [ 51.,  71.,  91.]],\n",
       "\n",
       "       [[102., 169., 236.],\n",
       "        [169., 236., 303.]],\n",
       "\n",
       "       [[164., 272., 380.],\n",
       "        [272., 380., 488.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_new = np.empty((3, 2, 3))\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        w_new[:,i,j] = np.sum(x_[i, j:j+2]*loss_, axis=1)\n",
    "        \n",
    "w_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# X_train = X_train.reshape(-1, 784)\n",
    "# X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, W, B):\n",
    "        self.W = W\n",
    "        self.B = B\n",
    "        self.lr = 1\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.N_in = x.shape[1] # 入力のサイズ（特徴量の数）...x.shape[1]に変更\n",
    "        self.P = 0 # Padding\n",
    "        self.F = self.W.shape[2] # フィルタのサイズ ...self.W.shape[2]に変更\n",
    "        self.S = 1 # stride\n",
    "        self.N_out = int((self.N_in + 2* self.P - self.F)/self.S + 1) # 𝑁𝑜𝑢𝑡  : 出力のサイズ（特徴量の数）\n",
    "        self.Z = x # 今回必要？\n",
    "        \n",
    "        self.A = np.empty((len(self.B), self.N_out))\n",
    "        for j in range(len(self.B)):\n",
    "            for i in range(self.N_out):\n",
    "                self.A[j,i] = np.sum(x[:,i:i + self.F]*self.W[j]) + self.B[j]  \n",
    "        print(self.A)\n",
    "        return self.A\n",
    "\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = dA  # 今回必要？\n",
    "        \n",
    "        dZ = np.empty((self.X.shape[0], self.N_in)) # (2, 4)\n",
    "        for i in range(self.X.shape[0]): # 2→入力ch \n",
    "            for j in range(self.N_in): # N_in = ４→Xの特徴量\n",
    "                output_ch_list = np.empty((self.W.shape[0], self.F)) #(3, 3)\n",
    "                for k in range(self.W.shape[0]): # 3→w.shape[0]→出力ch\n",
    "                    for l in range(self.F): # Wの数 = 3\n",
    "                        val = j - l\n",
    "                        if val < 0 or val > self.N_out -1:\n",
    "                            output_ch_list[k, l] = 0\n",
    "                        else:\n",
    "                            output_ch_list[k, l] = dA[k,val]*self.W[k,i,l] \n",
    "                dZ[i, j] = np.sum(output_ch_list)\n",
    "        print(dZ)\n",
    "#         pdb.set_trace() \n",
    "        self.dZ = dZ       \n",
    "\n",
    "        return dZ\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.forward(X)\n",
    "        dA = np.array( [[ 9, 11],[32, 35],[52, 56]])\n",
    "        self.backward(dA)\n",
    "#         pdb.set_trace() \n",
    "        # w 更新\n",
    "        new_W = np.empty((self.W.shape[0], self.W.shape[1], self.F))\n",
    "        for i in range(self.W.shape[1]):\n",
    "            for j in range(self.F):\n",
    "#                 pdb.set_trace()\n",
    "                new_W[:, i, j] = np.sum(self.X[i, j:j+self.N_out]*dA, axis=1)\n",
    "        self.W = new_W\n",
    "        \n",
    "        \n",
    "        # b 更新  \n",
    "        new_B = np.sum(dA, axis=1)\n",
    "        self.B = new_B \n",
    "#         pdb.set_trace() \n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        self.forward_propagation_func(X)\n",
    "        return np.argmax(self.z3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21. 29.]\n",
      " [18. 25.]\n",
      " [18. 24.]]\n",
      "[[125. 230. 204. 113.]\n",
      " [102. 206. 195. 102.]]\n",
      "a: [[21. 29.]\n",
      " [18. 25.]\n",
      " [18. 24.]]\n",
      "delta_b: [ 20  67 108]\n",
      "delta_w: [[[ 31.  51.  71.]\n",
      "  [ 51.  71.  91.]]\n",
      "\n",
      " [[102. 169. 236.]\n",
      "  [169. 236. 303.]]\n",
      "\n",
      " [[164. 272. 380.]\n",
      "  [272. 380. 488.]]]\n",
      "delta_x: [[125. 230. 204. 113.]\n",
      " [102. 206. 195. 102.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ = np.array([[1,2,3,4],\n",
    "               [2,3,4,5]])\n",
    "\n",
    "w_ = np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "\n",
    "b_ = np.array([1,2,3])\n",
    "\n",
    "sample = Conv1d(w_, b_)\n",
    "y = np.array([30, 110, 170, 140]) # fit用の仮値\n",
    "sample.fit(x_, y)\n",
    "print('a:', sample.A)\n",
    "print('delta_b:', sample.B)\n",
    "print('delta_w:', sample.W)\n",
    "print('delta_x:', sample.dZ)\n",
    "\n",
    "# aの答え\n",
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。\n",
    "x_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題5】（アドバンス課題）パディングの実装\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "\n",
    "最も単純なパディングは全て0で埋める ゼロパディング であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。\n",
    "\n",
    "\n",
    "numpy.pad — NumPy v1.17 Manual\n",
    "\n",
    "\n",
    "【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。\n",
    "\n",
    "\n",
    "【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 **平滑化** を行なってください。\n",
    "\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "#         self.n_nodes1 = n_nodes1\n",
    "#         self.n_nodes2 = n_nodes2\n",
    "\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "#         self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "        self.W = self.initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = self.initializer.B(n_nodes2)\n",
    "        self.H_W = 0\n",
    "        self.H_B = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.Z = x # 前のレイヤーのZを取得\n",
    "        A = x@self.W + self.B\n",
    "        \n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "\n",
    "        dZ = dA@self.W.T # このレイヤーのW\n",
    "\n",
    "        # 更新\n",
    "        self.B_dash = np.mean(dA, axis=0)\n",
    "        self.W_dash = self.Z.T@dA # 前のレイヤーのZ\n",
    "        self = self.optimizer.update(self) # この引数のselfはこの\"class FCのインスタンス自体\"を取得している。\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=42):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)       \n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        # layerの引数は\"class FCのインスタンス自体\"を取得している。\n",
    "\n",
    "        layer.B -= self.lr*layer.B_dash # B更新\n",
    "        layer.W -= self.lr*layer.W_dash # W更新\n",
    "\n",
    "\n",
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        # layerの引数は\"class FCのインスタンス自体\"を取得している。\n",
    "        H_B =layer.H_B + layer.B_dash**2\n",
    "        H_W =layer.H_W + layer.W_dash**2 \n",
    "        layer.B -= self.lr/np.sqrt(H_B + 0.1)*layer.B_dash # B更新\n",
    "        layer.W -= self.lr/np.sqrt(H_W + 0.1)*layer.W_dash # W更新\n",
    "        layer.H_B = H_B\n",
    "        layer.H_W = H_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def cross_entropy_func(self, x, y):\n",
    "        li = np.empty(len(x))\n",
    "        for i in range(len(x)):\n",
    "            lj = np.empty(10) # 10 = self.n_output, 最終的に変数にする\n",
    "            for j in range(10): # 10 = self.n_output, 最終的に変数にする\n",
    "                lj[j] = y[i,j]*np.log(x[i,j])\n",
    "            li[i] = sum(lj)\n",
    "        self.l = sum(li)/-10 # 10 = self.n_output, 最終的に変数にする\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_max = np.max(x, axis=1)\n",
    "        exp_x = np.exp(x - x_max.reshape(-1, 1))\n",
    "        sum_exp_x = np.sum(exp_x, axis=1).reshape(-1, 1)  \n",
    "        return exp_x/sum_exp_x\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        self.cross_entropy_func(x, y)\n",
    "        return x - y\n",
    "\n",
    "\n",
    "      \n",
    "class Tanh:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.A = x # backwardの引数のためのAを保管\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*(1 - np.tanh(self.A)**2)\n",
    "\n",
    "class Sigmoid:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.A = x # backwardの引数のためのAを保管\n",
    "        return 1.0 / (1.0 + np.exp(-x)) \n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*(1 - np.tanh(self.A)**2)\n",
    "    \n",
    "class ReLU:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.F = np.where(x > 0, 1, 0) # backwardの引数のためのAを保管\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def backward(self, x):\n",
    "        return x*self.F\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xavier:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Xavierの初期値\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.sigma = 1/np.sqrt(n_nodes1) # self.batch_sizeかも\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)       \n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "\n",
    "    \n",
    "class He:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Xavierの初期値\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.sigma = np.sqrt(2/n_nodes1) \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)       \n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier_2:\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=None, batch_size=20, a=0.01, n_epoch=5):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = a\n",
    "        self.n_epoch = n_epoch\n",
    "\n",
    "    def cross_entropy_func(self, X, y):\n",
    "        li = np.empty(len(X))   \n",
    "        for i in range(len(X)):\n",
    "            lj = np.empty(self.n_output)\n",
    "            for j in range(self.n_output):\n",
    "                lj[j] = y[i,j]*np.log(X[i,j])\n",
    "            li[i] = sum(lj)\n",
    "        self.l = sum(li)/-self.n_output\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # self.sigma : ガウス分布の標準偏差\n",
    "        # self.lr : 学習率\n",
    "        self.n_features = 784\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 = 200\n",
    "        self.n_output = 10\n",
    "        self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "\n",
    "        # self.n_nodes1 : 1層目のノード数\n",
    "        # self.n_nodes2 : 2層目のノード数\n",
    "        # self.n_output : 出力層のノード数\n",
    "        \n",
    "# fitメソッド内        \n",
    "        optimizer = AdaGrad(self.lr)\n",
    "        self.Conv1d = Conv1d(w_, b_)\n",
    "        self.activation1 = Tanh()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, Xavier(self.n_nodes1), optimizer)\n",
    "        self.activation2 = Tanh()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, Xavier(self.n_nodes2), optimizer)\n",
    "        self.activation3 = Softmax()\n",
    "# ミニバッチ        \n",
    "        get_mini_batch = GetMiniBatch(X, y, batch_size = self.batch_size)\n",
    "        self.l_list = np.empty(self.n_epoch)\n",
    "        self.l_val_list = np.empty(self.n_epoch)\n",
    "        self.cnt = 0\n",
    "        self.cnt_list = []\n",
    "        for i in range(self.n_epoch):\n",
    "            for X_mini, y_mini in get_mini_batch:\n",
    "# イテレーションごとのフォワード        \n",
    "                A1 = self.Conv1d.forward(X_mini)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "# イテレーションごとのバックワード\n",
    "                dA3 = self.activation3.backward(Z3, y_mini) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.Conv1d.backward(dA1) # dZ0は使用しない        \n",
    "# 評価（クロスエントロピー誤差）\n",
    "            # X, y\n",
    "            A1 = self.Conv1d.forward(X)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            A2 = self.FC2.forward(Z1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            A3 = self.FC3.forward(Z2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            self.cross_entropy_func(Z3, y)\n",
    "            self.l_list[i] = self.l\n",
    "            self.cnt += 1\n",
    "            self.cnt_list.append(self.cnt)    \n",
    "            # X_val, y_val\n",
    "            A1 = self.Conv1d.forward(X_val)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            A2 = self.FC2.forward(Z1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            A3 = self.FC3.forward(Z2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            self.cross_entropy_func(Z3, y_val)\n",
    "            self.l_val_list[i] = self.l                \n",
    "                \n",
    "                \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.Conv1d.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        \n",
    "        return np.argmax(Z3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "model = ScratchDeepNeuralNetrowkClassifier()\n",
    "model.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14fabbed0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set()\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(model.cnt_list, model.l_list, label='train')\n",
    "plt.plot(model.cnt_list, model.l_val_list, label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655833333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794375\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = model.predict(X_train)\n",
    "y_true_tr = np.argmax(y_train, axis=1)\n",
    "\n",
    "print(accuracy_score(y_true_tr, y_pred_tr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
